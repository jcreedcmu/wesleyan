\documentclass{article}
\usepackage[tmargin=0.15in, bmargin=0.15in]{geometry}
\input{theorem}
\input{prooftree}
\usepackage{relsize}
\usepackage{stmaryrd}
\usepackage{latexsym}
\usepackage{yfonts}
\usepackage{amsmath}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{tikz}
\usetikzlibrary{calc,arrows,cd,decorations.pathreplacing}
\usetikzlibrary{decorations.pathmorphing}
\usepackage{tcolorbox}
\tcbuselibrary{breakable}
\usepackage{listings}
\lstset{basicstyle=\ttfamily\footnotesize,breaklines=true}


\input{linear}
\def\chan{\overline}
\def\tnot{{\sim}}
\def\rfalse{\mathop\mathsf{false}}
\def\tensoru{\tensor\!\!|\,}
\def\lolu{\lol\!\!|\,}
\def\ampu{\amp\!\!|\,}
\def\tok#1{\mathop{\mathbf{#1}}}
\def\dns{{\downarrow}}
\def\ups{{\uparrow}}
\def\erule#1#2{\begin{prooftree}#1\justifies #2\end{prooftree}}
\def\tensor{\otimes}
\def\fut#1{\{#1\}}
\def\wrt#1{\langle #1\rangle}
\def\lc{\mathrel{\hat :}}
\def\x{\times}
\author{Jason Reed}

\begin{document}

\def\
\tikzset{
   commutative diagrams/.cd,
   arrow style=tikz,
   diagrams={>=stealth}}

%% \setcounter{section}{-1}
%% \section{Some Thoughts About Sessions And Futures}
%% Where in session types we'd say
%% \[
%% \erule
%% {\Delta, y : A, x : B \prov P :: T}
%% {\Delta, x : A \tensor B \prov x(y).P :: T}
%% \]
%% I'd rather say something more like
%% \[
%% \erule
%% {
%% \[
%% \Delta, y \lc \fut A, x' \lc \fut B \prov P :: T
%% \justifies
%% \Delta, z \lc \fut A \tensor \fut B \prov \blet (y, x') = z \bin P :: T
%% \]
%% }
%% {\Delta, x \lc \fut{\fut A \tensor \fut B} \prov x(z). \blet (y, x') = z \bin P :: T}
%% \]
%% and instead of
%% \[
%% \erule{\Delta \prov P :: (y:A) \qquad \Delta' \prov Q :: (x : B)}
%% {\Delta, \Delta' \prov (\nu y) x \wrt y . (P \celse Q) :: (x : A \tensor B)}
%% \]
%% I'd say
%% \[
%% (\nu xy) (P \celse Q \celse x(x_v).y(y_v).\pair {x_v}{y_v}) :: A \tensor B
%% \]
%% with the general rules being perhaps something like
%% \[
%% \erule
%% {\Delta, y \lc A \prov P :: T}
%% {\Delta, x \lc \fut A \prov x(y).P :: T}
%% \]
%% \[
%% \erule
%% {\Delta, x : \fut A \prov P  : \sharp \qquad \Delta', y : [A] \prov P : \sharp}
%% {\Delta,\Delta' \prov \nu x.(P\celse Q) :: T}
%% \]
%% Ack, no, this is a classical cut, what am I doing.

%% \subsection{The Type Translation}
%% {\em Session} types
%% \[
%% \begin{tabular}{rccl}
%% Session Types&$A$&$::=$&$A \tensor B \celse A \lol B \celse \cdots$
%% \end{tabular}
%% \]
%% are a thing, and I mean to translate them to futures somehow. A session
%% has a distinguished channel. The distinguished channel of an $A \tensor B$-typed
%% process has an $A$ written to it, and then the process after that transition
%% now has session type $B$.

%% There is a term-translation I have in my head that is merely forcing all channels to be
%% linear. It takes a read like $x(z).P$ and changes it to $x(z, x').[x'/x]P$. Every time
%% you would have read some data and potentially changed the expectations of the channel
%% it was read along, instead you `CPS-ify' the continuation channel into a fresh one.
%% What happens with writes? I guess every time I do a write $x\wrt y.P$ it changes to
%% $(\nu x') x\wrt{y,x'}.[x'/x]P$. Writes consume the channel also.

%% Do I change synchronous rules to simply produce {\em the data} they want to write instead
%% of a $\sharp$-typed classical sequent?

%% If I just do the translation I said to
%% \[
%% \erule
%% {\Delta, y : A, x : B \prov P :: T}
%% {\Delta, x : A \tensor B \prov x(y).P :: T}
%% \]
%% I get
%% \[
%% \erule
%% {\Delta, y : A, x' : B \prov P :: T}
%% {\Delta, x : A \tensor B\prov x(y, x').P :: T}
%% \]
%% ?
%% \subsection{Ternary $\tensor$}
%% There should be a legitimate form of ternary tensor even
%% in Caires-Pfenning, like
%% \[
%% \erule
%% {\Delta, y_1 : A_1, y_2 : A_2, x : B \prov P :: T}
%% {\Delta, x : \tensor\{A_1 A_2 B\} \prov x(y_1, y_2).P :: T}
%% \]
%% \[
%% \erule{
%% \Delta_1 \prov P_1 :: (y_1:A_1)\qquad
%% \Delta_2 \prov P_2 :: (y_2:A_2)\qquad
%%   \Delta \prov Q :: (x : B)}
%% {\Delta_1, \Delta_2, \Delta \prov (\nu y_1y_2) x \wrt {y_1,y_2} . (P_1 \celse P_2 \celse Q)
%% :: (x : \tensor \{A_1A_2B\})}
%% \]

%% I think the type mapping I have in mind smells like
%% \[(A \tensor B)^* = \tensor\{A^* B^* 1\} \]
%% \[(A \& B)^* = ? \]
%% Dang, I don't know where I'm going here.

%% I want to picture a fairly ordinary lambda calculus with channel types like
%% $\fut A$
%%  that stay the same and have actual values
%% passed along them.

%% A process with a channel that is session-typed $A \tensor B$ is a channel
%% that provides an $A$, and also a $\fut B$. So perhaps

%% \[(A \tensor B)^* = \fut{A^* \x \fut {B^*}}\]
%% \[(A \amp B)^* = \fut{A^* \amp B^*}\]
%% No... hm. No matter what, if I have
%% \[\Delta \prov P :: T\]
%% then $T$ is notionally a {\em channel} type, so I should devise the translation
%% to not involve $\fut{}$. The theorem will be something like
%% \begin{theorem}
%% If
%% $\Delta \prov P :: T$
%% then $\fut{\Delta^*} \prov P^* :: T^*$.
%% \end{theorem}
%% and maybe
%% \[(A \tensor B)^* = A^* \x \fut {B^*}\]
%% \[(A \amp B)^* = \fut{A^*} \amp \fut{B^*}\]
%% \subsection{Maybe I Should Think About Focusing}
%% When I have a {\em positive} prop on the right, what's going on is
%% that I'm {\em writing} to a channel. When I have a negative prop on the
%% right, what's going on is that I'm reading from a channel.

%% A {\em goal} of $A \tensor B$ is like having
%% \[\lnot ( A \x \lnot(\lnot B )) \]
%% We can make progress if we provide an $A$, and provide some continuation for what to do
%% when our counterparty provides us a $B$-sink.

%% Maybe it goes like this: in right focus, we are really building a value.
%% With some positive prop on the right, we are committed to eventually write something
%% to a channel. In left focus, we have read a value and we're decomposing it. An
%% unfocused negative prop on the left is just some channel we can write to.
%% A negative prop on the right reads from the channel, a positive prop on the left
%% reads from a channel.

%% Perhaps the session-typed $A \tensor B$ is something like $\ups (A \tensor \dns\ups B)$.

%% \[
%% \erule
%% {\Delta \prov v : [P] \qquad \Delta' \prov v' : [P']}
%% {\Delta, \Delta' \prov \pair v {v'} : [P \tensor P']}
%% \]
%% \[
%% \erule
%% {\Delta \prov E :: (x : N)}
%% {\Delta \prov \tok{thunk} x.E : [\dns N]}
%% \]
%% \[
%% \erule
%% {\Delta \prov E :: (x : P)}
%% {\Delta \prov  E :: (x : \ups P)}
%% \]
%% \[
%% \erule
%% {\Delta, y : P \prov E :: (x : Q)}
%% {\Delta[\ups P] \prov \tok{end} y.E : (x : Q)}
%% \]
%% \[
%% \erule
%% {\Delta, y : N \prov E :: (x : Q)}
%% {\Delta, y : \dns N \prov  E :: (x : Q)}
%% \]

%% \[
%% \erule
%% {\Delta \prov v : [P]}
%% {\Delta \prov x\wrt v :: (x : P)}
%% \]
%% \[
%% \erule
%% {\Delta [N] \prov S :: (x : Q)}
%% {\Delta, y : N \prov y\wrt S  :: (x : Q)}
%% \]

%% This is confusing, but tantalizingly close to what happens in the
%% focusing-creating translation. The one I have in mind is where we translate
%% everything into positives:
%% \[
%%  (P \tensor P)^* = P^* \tensor P^*
%% \qquad
%%  (P \oplus P)^* = P^* \oplus P^*
%% \]
%% \[ (P \lol N)^\phi = P^* \tensor N^\phi
%% \qquad
%%  (N \amp N)^\phi = N^\phi \oplus N^\phi \]
%% \[ (\ups P)^\phi = P^* \to \#(\phi) \]
%% \[ (\dns N)^* = \forall \phi . N^\phi \to \#(\phi) \]
%% and we have like
%% \[ \Gamma \prov P \quad\Leftrightarrow\quad (\dns\Gamma)^*, (\ups P)^\phi \prov \#(\phi)\]
%% \[ \Gamma \prov [P] \quad\Leftrightarrow\quad (\dns\Gamma)^* \prov [P^*]\]
%% \[ \Gamma[N] \prov Q \quad\Leftrightarrow\quad (\dns\Gamma)^*, (\ups Q)^\phi \prov [N^\phi]\]
%% \[ \Gamma, P \prov Q \quad\Leftrightarrow\quad (\dns\Gamma)^*, (\ups Q)^\phi, P^* \prov \#(\phi)\]
%% \[ \Gamma \prov N \quad\Leftrightarrow\quad (\dns\Gamma)^*, N^\phi \prov \#(\phi)\]

%% Let's look at how a case compiles down.
%% \[
%% \erule
%% { y : N \prov e : P \qquad  y' : N' \prov e' : P}
%% { x : N \oplus N' \prov \bcase x \bof y.e \celse y'.e' : P}
%% \]
%% \[
%% \mapsto \erule
%% {
%% \[
%% \[ y : (\dns N)^*, k : (\ups P)^\phi \prov e : \#(\phi) \qquad
%%   y' : (\dns N')^*, k : (\ups P)^\phi \prov e' : \#(\phi)
%% \justifies
%%  k : (\ups P)^\phi, q : (\dns N \oplus \dns N')^* \prov {\bcase} : \#(\phi)
%% \]
%% \justifies
%%  k : (\ups P)^\phi \prov {\lambda q . \bcase} : [\ups(\dns N \oplus \dns N')^\phi]
%% \]}
%% { x : (\dns\ups(\dns N \oplus \dns N'))^*, k : (\ups P)^\phi \prov {x [\phi] \lambda q . \bcase} : \#(\phi) }
%% \]
%% What about tensor R, say?
%% \[
%% \begin{prooftree}
%% \[
%% \[
%% y : (\ups P)^\psi \prov ? : \#(\psi)
%% \justifies
%%  \prov ? : [(\dns \ups P)^* ]
%% \]
%% \[
%% \[
%% \justifies
%% y : (\ups \dns \ups P')^\psi \prov ? : \#(\psi)
%% \]
%% \justifies
%%  \prov ? : [ (\dns\ups\dns\ups P')^*]
%% \]
%% \justifies
%%  \prov ? : [(\dns \ups P \tensor \dns\ups\dns\ups P')^*]
%% \]
%% \justifies
%% x : (\ups (\dns \ups P \tensor \dns\ups\dns\ups P'))^\phi \prov ? : \#(\phi)
%% \end{prooftree}
%% \]
%% I can't see where the asymmetry comes from, hmm.
%% \subsection{Do I even need $\phi$?}
%% I do after all have linearity around.
%% I could try something like
%% \[
%%  (P \tensor P)^* = P^* \tensor P^*
%% \qquad
%%  (P \oplus P)^* = P^* \oplus P^*
%% \]
%% \[ (P \lol N)^* = P^* \tensor N^*
%% \qquad
%%  (N \amp N)^* = N^* \oplus N^* \]
%% \[ (\ups P)^* = P^* \lol \# \]
%% \[ (\dns N)^* = N^* \lol \# \]
%% This would make the case
%% \[
%% \erule
%% { y : N \prov e : P \qquad  y' : N' \prov e' : P}
%% { x : N \oplus N' \prov \bcase x \bof y.e \celse y'.e' : P}
%% \]
%% \[
%% \mapsto \erule
%% {
%% \[
%% \[ y : (\dns N)^*, k : (\ups P)^* \prov e : \# \qquad
%%   y' : (\dns N')^*, k : (\ups P)^* \prov e' : \#
%% \justifies
%%  k : (\ups P)^*, q : (\dns N \oplus \dns N')^* \prov {\bcase\ q \bof \cdots} : \#
%% \]
%% \justifies
%%  k : (\ups P)^* \prov {\lambda q . \bcase\ q \bof \cdots} : [\ups(\dns N \oplus \dns N')^*]
%% \]}
%% { x : (\dns\ups(\dns N \oplus \dns N'))^*, k : (\ups P)^* \prov {x\  \lambda q . \bcase\ q \bof \cdots} : \# }
%% \]
%% and actual $\oplus L$ in session types looks like
%% \[
%% \erule
%% {\Delta, x : A \prov P :: T \qquad \Delta, x:B \prov Q :: T}
%% {\Delta, x : A \oplus B \prov x .\tok{case}(P, Q) :: T}
%% \]

%% And for comparison,
%% \[
%% \erule
%% { y : N \prov e : P \qquad  y : N \prov e' : P'}
%% {y : N \prov e : P \amp P' }
%% \]
%% \[
%% \mapsto \erule
%% {
%% \[
%% \[ y : (\dns N)^*, k : (\ups P)^* \prov e : \# \qquad
%%   y : (\dns N)^*, k : (\ups P)^* \prov e' : \#
%% \justifies
%%  y : (\dns N)^*, q : (\ups P \amp \ups P')^* \prov {\bcase\ q \bof \cdots} : \#
%% \]
%% \justifies
%%  y : (\dns N)^* \prov {\lambda q . \bcase\ q \bof \cdots} : [\dns(\ups P \oplus \dns P')^*]
%% \]}
%% { k : (\ups\dns(\ups P \amp \ups P'))^*, y : (\dns N)^* \prov {k\  \lambda q . \bcase\ q \bof \cdots} : \# }
%% \]
%% So let's just do the minimal $\tensor R$ case and see what shape it has.
%% \[
%% \erule
%% {\Delta \prov e : P \qquad \Delta' \prov e' : P' }
%% {\Delta,\Delta'  \prov \pair{e}{e'} : P \tensor P'}
%% \mapsto \]

%% \[
%% \begin{prooftree}
%% \[
%% \[
%% \Delta, k : (\ups P)^* \prov e : \#
%% \justifies
%% \Delta \prov \lambda k . e : [(\dns \ups P)^* ]
%% \]
%% \[
%% \Delta', k' : ( \ups P')^* \prov e' : \#
%% \justifies
%% \Delta' \prov \lambda k' . e' : [ (\dns\ups P')^*]
%% \]
%% \justifies
%% \Delta, \Delta' \prov \pair{\lambda k .e}{\lambda k'.e'} : [(\dns \ups P \tensor \dns\ups P')^*]
%% \]
%% \justifies
%% \Delta, \Delta', K : (\ups (\dns\ups P \tensor \dns\ups P'))^* \prov K\ \pair{\lambda k .e}{\lambda k'.e'} : \#
%% \end{prooftree}
%% \]
%% This feels like what the future-session-typed rule ought to look like. Something like
%% taking
%% \[
%% \erule{\Delta \prov P :: (y:A) \qquad \Delta' \prov Q :: (x : B)}
%% {\Delta, \Delta' \prov (\nu y) x \wrt y . (P \celse Q) :: (x : A \tensoru B)}
%% \]
%% (where $A \tensoru B$ is the version of $\tensor$ that preserves the
%% channel into $B$) and instead doing
%% \[
%% \erule{\Delta \prov P :: (y:A) \qquad \Delta' \prov Q :: (z : B)}
%% {\Delta, \Delta' \prov (\nu yz) x \wrt{y, z} . (P \celse Q) :: (x : A \tensor B)}
%% \]
%% Where the term translation again is a thing that affects reads and writes by
%% \[
%% x\wrt t . P \quad \mapsto\quad \nu z . x \wrt{t,z} . [z/x]P
%% \]
%% \[
%% x(y) . Q \quad \mapsto\quad  x (y,w) . [w/x]Q
%% \]
%% Before the translation I'd do a communication
%% \[ x\wrt t . P \celse x(y) . Q \quad \to \quad P \celse  [t/y] Q  \]
%% after the translation I do
%% \[
%% (\nu z . x \wrt{t,z} . [z/x]P) \celse
%% (x (y,w) . [w/x]Q)
%%  \quad \to  \quad
%%  x \wrt{t,z} . [z/x]P \celse
%% x (y,w) . [w/x]Q
%% \]
%% \[
%%   \to  \quad
%%   [z/x]P \celse
%%  [t/y][z/w][w/x]Q
%% \ \equiv\ %
%%   [z/x]P \celse [t/y][z/x]Q
%% \ \equiv\ %
%%   P \celse [t/y]Q
%% \]
%% What's $\tensor L$ in this setting, then?
%% \[
%% \erule
%% {\Delta, y : A, x : B \prov P :: T}
%% {\Delta, x : A \tensoru B \prov x(y).P :: T}
%% \]
%% becomes
%% \[
%% \erule
%% {\Delta, y : A, w : B \prov P :: T}
%% {\Delta, x : A \tensor  B \prov x(y,w).P :: T}
%% \]
%% \subsection{Implication}
%% Channel-preserving process assignment for implication goes like
%% \[
%% \erule
%% {\Delta, y : A \prov P :: (x : B)}
%% {\Delta \prov x(y).P :: (x : A \lolu B)}
%% \]
%% \[
%% \erule{\Delta \prov P :: (y:A) \qquad \Delta', x : B \prov Q :: T}
%% {\Delta, \Delta', (x : A \lolu B) \prov (\nu y) x \wrt y . (P \celse Q) :: T}
%% \]
%% and non-preserving like
%% \[
%% \erule
%% {\Delta, y : A \prov P :: (w : B)}
%% {\Delta \prov x(y, w).P :: (x : A \lol B)}
%% \]
%% \[
%% \erule{\Delta \prov P :: (y:A) \qquad \Delta', z : B \prov Q :: T}
%% {\Delta, \Delta', (x : A \lol B) \prov (\nu yz) x \wrt {y, z} . (P \celse Q) :: T}
%% \]
%% \subsection{Channel Reuse for Additives}
%% Let's try additive conjunction. Preserving like
%% \[
%% \erule
%% {\Delta \prov P :: (x : A)
%% \qquad \Delta \prov Q :: (x : B)}
%% {\Delta \prov x(y).\bcase y.(P\celse Q) :: (x : A \ampu B)}
%% \]
%% \[
%% \erule
%% {\Delta, x : A \prov P :: T}
%% {\Delta, x : A \ampu B\prov x\wrt\binl.P :: T}
%% \qquad
%% \erule
%% {\Delta, x : B \prov P :: T}
%% {\Delta, x : A \ampu B\prov x\wrt\binr.P :: T}
%% \]
%% and non-preserving like
%% \[
%% \erule
%% {\Delta \prov P :: (w : A)
%% \qquad \Delta \prov Q :: (w : B)}
%% {\Delta \prov x(y, w).\bcase y.(P\celse Q) :: (x : A \amp B)}
%% \]
%% \[
%% \erule
%% {\Delta, z : A \prov P :: T}
%% {\Delta, x : A \amp B\prov \nu z . x\wrt{\binl,z}.P :: T}
%% \qquad
%% \erule
%% {\Delta, z : B \prov P :: T}
%% {\Delta, x : A \amp B\prov \nu z . x\wrt{\binr,z}.P :: T}
%% \]

%% \subsection{Polarizing Translation}
%% Given unpolarized props, we can talk about the `fully polarizing' translations
%% $A_+$ and $A_-$ that go

%% \[\begin{tabular}{l|l|l}
%%   $A$&$A_+$&$A_-$\\
%% \hline
%%   $A \otimes B$&$ \dns  A^+ \otimes \dns  B^+ $&$ \ups (  A^- \otimes  B^-)$\\
%%   $A \oplus B$&$ \dns A^+ \oplus \dns B^+ $&$ \ups( A^- \oplus  B^-)$\\
%%   $A \imp B$&$ \dns (A^- \imp  B^+) $&$  \dns A^+ \imp  \ups B^-$\\
%%   $A \amp B$&$ \dns (A^+ \amp  B^+) $&$  \ups A^- \amp  \ups B^-$\\
%% \end{tabular}\]
%% where $A^- = \dns A_-$ and $A^+ = \ups A_+$.
%% If we have a sequent like $ \Gamma_-  \prov  C_+$.

%% So what's the theorem?
%% Suppose I have a proof of a proposition. I can do the session-types process-assignment to
%% it. I can do the non-channel-preserving session-types process-assignment to it.

%% But separately, I can take a proof of $\Gamma \prov C$ and turn it into a proof
%% of $\Gamma_- \prov C_+$. I can turn {\em that} into a proof of $(\Gamma_-)^* \prov (C_+)^*$.
%% And then I think I can do a certain process-assignment to {\em that}, and get the same answer
%% as before.

%% \subsection{Focusing Process Assignment}

%% The judgment for focus is
%% \[ \Delta ; \Xi \prov e : [R]\]
%% The context $\Xi$ is residuated channel variables for sending to $\nu$.
%% The expression $v$ is a value to send to a channel, and $\rho$s are process
%% expressions. We say
%% \[
%% \erule
%% {\Delta_1 ; \Xi_1 \prov v_1; \rho_1 : [R_1] \qquad \Delta_2 ; \Xi_2 \prov v_2; \rho_2 : [R_2]
%% \using \tensor R}
%% {\Delta_1, \Delta_2 ; \Xi_1, \Xi_2 \prov \pair {v_1} {v_2} ; (\rho_1 \celse \rho_2) : [R_1 \tensor R_2]}
%% \]
%% \[
%% \erule
%% {\Delta ; \Xi \prov v; \rho : [R_1] \using \oplus R_1}
%% {\Delta ; \Xi \prov \binl v; \rho : [R_1 \oplus R_2]}
%% \qquad
%% \erule
%% {\Delta ; \Xi \prov v; \rho : [R_2] \using \oplus R_2}
%% {\Delta ; \Xi \prov \binr v; \rho : [R_1 \oplus R_2]}
%% \]
%% \[
%% \erule
%% {\Delta, x : R \prov \rho ::  \# \using \tnot R}
%% {\Delta; c \prov \tok{chan} x ; c(x).\rho :: [\tnot R]}
%% \]
%% \[
%% \erule
%% {\Delta; \Xi \prov v ; \rho :: [R] \using focR}
%% {\Delta \prov (\nu \Xi )c\wrt v.\rho :: (c : R)}
%% \]
%% \[
%% \erule
%% {\Delta; \Xi \prov v ; \rho :: [R] \using focL}
%% {\Delta, c : R\rfalse  \prov (\nu \Xi)c\wrt v.\rho :: \#}
%% \]
%% \[
%% \erule
%% {\Delta, x_1 : R_1, x_2 : R_2 \prov \rho :: T \using \tensor L}
%% {\Delta, x : R_1 \tensor R_2 \prov \blet \pair {x_1}{x_2} = x \bin \rho :: T}
%% \]
%% \[
%% \erule
%% {\Delta, x_1 : R_1 \prov \rho_1 :: T \qquad
%% \Delta, x_2 : R_2 \prov \rho_2 :: T
%%  \using \oplus L}
%% {\Delta, x : R_1 \oplus R_2 \prov \bcase x \bof x_1.\rho_1 | x_2.\rho_2 :: T}
%% \]
%% \[
%% \erule
%% {\Delta, c : R \rfalse \prov \rho :: T \using \tnot L}
%% {\Delta, x : \tnot R \prov \blet \tok{chan} x = c \bin \rho :: T}
%% \]

%% Maybe $focR$ never comes up?

%% Let's do examples. Let's warm up with a write, say $\tensor R$.
%% \[
%% \begin{prooftree}
%% \[
%% \[
%% \[
%% \Delta, d :  R\rfalse \prov \rho :: \#
%% \justifies
%% \Delta, d : \tnot R \prov \rho :: \#
%% \]
%% \justifies
%%  \Delta; d \prov  \chan{d} ;  \rho : [ \tnot\tnot R]
%% \]
%% \[
%% \[
%% \Delta', d' :  R' \rfalse \prov \rho' :: \#
%% \justifies
%% \Delta', d' :  \tnot R' \prov \rho' :: \#
%% \]
%% \justifies
%%  \Delta'; d' \prov  \chan{d'} ;  \rho' : [ \tnot\tnot R']
%% \]
%% \justifies
%% \Delta, \Delta'; d,d' \prov \pair {\chan d} {\chan{d'}} ; (\rho \celse \rho') : [\tnot \tnot R \tensor \tnot\tnot R']
%% \]
%% \using focL \justifies
%% \Delta, \Delta', c :  \tnot\tnot R \tensor \tnot\tnot R' \rfalse \prov (\nu dd')
%%  c\wrt{\chan d,\chan{d'}}.(\rho \celse \rho') :: \#
%% \end{prooftree}
%% \]
%% Hm, but I'm worried those $\tnot L$ decomps at the leaves want reads. Or maybe
%% I need to split up the semantics of the different shifts.

%% Something more like
%% \[
%% \begin{prooftree}
%% \[
%% \[
%% \Delta, d :  R\rfalse \prov \rho :: \#
%% \justifies
%%  \Delta; d \prov  \chan{d} ;  \rho : [ \dns\ups R]
%% \]
%% \[
%% \Delta', d' :  R' \rfalse \prov \rho' :: \#
%% \justifies
%%  \Delta'; d' \prov  \chan{d'} ;  \rho' : [ \dns\ups R']
%% \]
%% \justifies
%% \Delta, \Delta'; d,d' \prov \pair {\chan d} {\chan{d'}} ; (\rho \celse \rho') : [\dns\ups R \tensor \dns\ups R']
%% \]
%% \using focL \justifies
%% \Delta, \Delta', c :  \dns\ups R \tensor \dns\ups R' \rfalse \prov (\nu dd')
%%  c\wrt{\chan d,\chan{d'}}.(\rho \celse \rho') :: \#
%% \end{prooftree}
%% \]

%% so that the $\oplus L$ case looks like

%% \[
%% \erule
%% {
%% \[
%% \[
%% \[
%% \[
%% \justifies
%% \Delta,  c_1 : R_1\rfalse   \prov \rho_1 :: \#
%% \]
%% \justifies
%% \Delta, x_1 : \ups R_1   \prov \blet \tok{ch} c_1 = x_1 \bin \rho_1 :: \#
%% \]
%% \[
%% \[
%% \justifies
%% \Delta,   c_2 : R_2\rfalse  \prov \rho_2 :: \#
%% \]
%% \justifies
%% \Delta,  x_2:  \ups R_2  \prov \tok{ch} c_2 = x_2 \bin \rho_2 :: \#
%% \]
%% \justifies
%% \Delta, x :\ups R \oplus  \ups R'  \prov \bcase x\bof (\tok{ch} c_1.\rho_1)\celse(\tok{ch} c_2.\rho_2) :: \#
%% \]
%% \justifies
%% \Delta  \prov \lambda x.\bcase x\bof (\tok{ch} c_1.\rho_1)\celse(\tok{ch} c_2.\rho_2) : [\dns (\ups R \oplus  \ups R') \rfalse]
%% \]
%% }
%% {\Delta, c : \dns (\ups R \oplus  \ups R') \rfalse \prov c(x).\bcase x\bof (\tok{ch} c_1.\rho_1)\celse(\tok{ch} c_2.\rho_2) :: \#}
%% \]

%% \section{Introduction}
%% I'm going to sketch out what I think is a certain interesting way of
%% decomposing the way that processes are assigned to proofs in
%% intuitionistic linear logic. In the interested of getting to the meat
%% of the proofs I'm going to skip the exponential and atoms, but
%% obviously they ought to be dealt with. If this is already in the
%% literature somewhere I would definitely like to read it, but I
%% couldn't seem to find what I was looking for in Pfenning \&
%% Griffiths's ``Polarized Substructural Session Types'', which seemed
%% like the most likely place to look, given the title.

%% \section{Languages}
%% The unpolarized propositions I care about are
%% \[\hbox {Propositions } A ::= A \tensor A \celse A \oplus A \celse A \lol A \celse A \amp A \celse \cdots \]
%% The polarized propositions are
%% \[\hbox {Positive Props } P ::= \dns N \celse P \tensor P \celse P \oplus P \celse \cdots \]
%% \[\hbox {Negative Props } N ::= \ups P \celse P \lol N \celse N \amp N \celse \cdots \]
%% And at the end I'll want a language of `classical' positive propositions, which
%% contains all the usual positive propositional connectives, plus a single negative
%% connective with a built-in shift: a sort of negation, which uses an atomic negative
%% proposition $\#$.

%% \[\hbox {Classical Props } R ::= \tnot R \celse R \tensor R \celse R \oplus R \celse \cdots \]
%% This $\tnot R$ is basically $\dns(R \lol \#)$. We could make up
%% a judgment $\rfalse$ for its unfocused presence on the left, and
%% give inference rules (in an ambient focused
%% proof system) as
%% \[
%% \erule
%% {\Delta, R \prov \#}
%% {\Delta \prov [\tnot R]}
%% \qquad
%% \erule
%% {\Delta, R\rfalse \prov R'}
%% {\Delta, \tnot R \prov R'}
%% \qquad
%% \erule
%% {\Delta \prov [R]}
%% {\Delta, R\rfalse \prov \#}
%% \]

%% By indexing $\#$ with a parameter $\phi$, and having two different negations
%% (a binding quantifier $\N \phi . R$ that behaves like $\dns \forall \phi . (R(\phi) \lol \#(\phi))$ and
%% a $\tnot_\phi$ that behaves like $R \lol \#(\phi)$)
%% we could make this language not classical but constructive, instead, but I'm not sure that's
%% needed for the process interpretation.
%% \section{Translations}
%% \subsection{Polarizing Translation}
%% Given an unpolarized props $A$, the `fully unpolarized polarization' of $A$
%% into a positive (resp. negative) prop is $A_+$ (resp. $A_-$) by

%% \[\begin{tabular}{l|l|l}
%%   $A$&$A_+$&$A_-$\\
%% \hline
%%   $A \otimes B$&$ \dns  A^+ \otimes \dns  B^+ $&$ \ups (  A^- \otimes  B^-)$\\
%%   $A \oplus B$&$ \dns A^+ \oplus \dns B^+ $&$ \ups( A^- \oplus  B^-)$\\
%%   $A \imp B$&$ \dns (A^- \imp  B^+) $&$  \dns A^+ \imp  \ups B^-$\\
%%   $A \amp B$&$ \dns (A^+ \amp  B^+) $&$  \ups A^- \amp  \ups B^-$\\
%% \end{tabular}\]
%% where $A^- = \dns A_-$ and $A^+ = \ups A_+$.

%% \begin{lemma}
%% We have $\Delta \prov A$ in an unfocused proof system exactly
%% when (and with exactly as many proofs as) we have $\Delta^- \prov A^+$.
%% \end{lemma}

%% \begin{proof}
%% By induction. For example, to decompose $\oplus$ on the left, as
%% \[
%% \erule
%% {\Delta, A \prov C \qquad \Delta, B \prov C}
%% {\Delta, A \oplus B \prov C}
%% \]
%% corresponds exactly to choosing a focus (and being forced through the
%% asynchronous decomposition exactly one step) as
%% \[
%% \begin{prooftree}
%% \[
%% \[
%% \[
%%  \Delta_-, A_- \prov C_+
%% \justifies
%%  \Delta_-, \dns A_- \prov C_+
%% \]
%% \[
%%  \Delta_-, B_- \prov C_+
%% \justifies
%%  \Delta_-, \dns B_- \prov C_+
%% \]
%% \justifies
%%  \Delta_-, \dns A_- \oplus \dns B_- \prov C_+
%% \]
%% \justifies
%%  \Delta_-, [\ups(\dns A_- \oplus \dns B_-)] \prov C_+
%% \]
%% \justifies
%%  \Delta_-, \ups(\dns A_- \oplus \dns B_-) \prov C_+
%% \end{prooftree}
%% \]
%% \cqed
%% \end{proof}

%% \def\bfut{\mathbf{fut}}
%% \def\bpol{\mathbf{pol}}
%% \def\bproc{\mathbf{proc}}
%% \def\provf{\prov_\mathsf{f}}

%% \begin{lemma}
%% If $\Delta \prov e : A$, then $\Delta \prov_\pi \bproc(e) : A$
%% \end{lemma}

%% \begin{lemma}
%% If $\Delta \prov_\pi e : A$, then $\Delta \provf \bfut(e) : A$
%% \end{lemma}


%% \begin{lemma}
%% If $\Delta \prov e : A$, then $\Delta_- \prov \bpol(e) : A_+$
%% \end{lemma}

%% \begin{proof}

%% \cqed
%% \end{proof}

%% \begin{theorem}
%% Suppose we have a session-typing $\Delta \prov e : A$.
%% Then $\bfut (e) = \bpol(e)$
%% \end{theorem}

%% \begin{proof}

%% \cqed
%% \end{proof}

\def\ch{\bullet}
\section{Starting Over}

Let me distinguish read channels $c^<$ from write channels $d^>$ from values $x$.

Tensor write:
\[
\begin{prooftree}
\[
\[
c_1^{\overline{\pi_1}} : \lnot A^{\pi_1}_+ \prov  P : \#
\justifies
[c_1] \prov {{c_1^{\pi_1}}} / P : [ \lnot\lnot A^{\pi_1}_+  ]
\]
\[
c_2 : \lnot B_+ \prov  Q : \#
\justifies
[c_2] \prov {{c_2}} / Q : [ \lnot\lnot B_+  ]
\]
\justifies
[c_1, c_2] \prov \pair{{c_1}}{{c_2}} / (P\celse Q) : [ \lnot\lnot A_+ \tensor \lnot \lnot B_+ ]
\]
\justifies
  d^> : \lnot(\lnot\lnot A^{\pi_1}_+ \tensor \lnot \lnot B^{\pi_2}_+) \prov (\nu c_1c_2).d
\pair{{c_1^{\pi_1}}}{{c_2^{\pi_2}}}.(P\celse Q) : \#
\end{prooftree}
\]
Tensor read:
\[
\begin{prooftree}
\[
\[
\[
\justifies
y : \lnot A_- , z :  \lnot  B_- \prov  P  : \#
\]
\justifies
x : \lnot A_- \tensor \lnot  B_- \prov  \blet (y,z) = x \bin P  : \#
\]
\justifies
\prov \lambda x . \blet (y,z) = x \bin P  : [\lnot(\lnot A_- \tensor \lnot  B_-)]
\]
\justifies
  c : \lnot\lnot(\lnot A_- \tensor \lnot  B_-) \prov c(x).\blet (y,z) = x \bin P : \#
\end{prooftree}
\]
Lol write?
\[\begin{tabular}{rccl}
Value Types&$A^T$&$::=$&$A^T \tensor A^T \celse A^T \oplus A^T \celse T$\\
Read Types&$R$&$::=$&$ \lnot A^{C}$\\
Write Types&$W$&$::=$&$  A^{\lnot C}$\\
Channel Types&$C$&$::=$&$  R \celse W$
\end{tabular}\]

\[
\erule
{c :  C \prov P : \#}
{ \prov c/ c / P : [ \lnot C]}
\]

\[
\erule
{ \prov K_1 / {e_1} / P : [ A_1 ]
\qquad  \prov K_2 / {e_2} / Q : [ A_2 ]}
{ \prov K_1, K_2 / \pair{e_1}{e_2} / (P\celse Q) : [ A_1 \otimes A_2 ]]}
\]
\[
\erule
{ \prov K /{e} / P : [ A ]}
{d : A\prov (\nu K) d\wrt e.P :\#}
\]
\[\begin{tabular}{rccl}
Value Types&$A$&$::=$&$A \tensor A \celse A \oplus A \celse \lnot C$\\
Read Types&$R$&$::=$&$ \lnot  A$\\
Write Types&$W$&$::=$&$   A$\\
Channel Types&$C$&$::=$&$  R \celse W$
\end{tabular}\]

Nah, I'm confusing myself further. I really need to see all the examples together.
I don't know a priori whether channels are read or write.

Except... it seems like things should be focally consistent. Maybe
\[\begin{tabular}{rccl}
Value Types&$A$&$::=$&$A \tensor A \celse A \oplus A \celse \tok{ch} C$\\
Read Types&$R$&$::=$&$ \tok{rd}  A \celse \lnot W$\\
Write Types&$W$&$::=$&$ \tok{wr}  A \celse \lnot R$\\
Channel Types&$C$&$::=$&$  R \celse W$
\end{tabular}\]

\[
\erule
{c :  C \prov P : \#}
{ \prov c/ \tok{name} c / P : [ \tok{ch} C]}
\]

\[
\erule
{ \prov K_1 / {e_1} / P : [ A_1 ]
\qquad  \prov K_2 / {e_2} / Q : [ A_2 ]}
{ \prov K_1, K_2 / \pair{e_1}{e_2} / (P\celse Q) : [ A_1 \otimes A_2 ]]}
\]
\[
\erule
{ \prov K /{e} / P : [ A ]}
{d : \tok{wr} A\prov (\nu K) d\wrt e.P :\#}
\]

\[
\erule
{ c : C \prov J}
{x : \tok{ch} C \prov [\tok{get} x / c] J}
\]

\vfil\eject
Tensor write:
\[
\begin{prooftree}
\[
\[
{d_1} : \lnot A_+ \prov  P : \#
\justifies
[d_1] \prov {{d_1}} / P : [ \lnot\lnot A_+  ]
\]
\[
d_2 : \lnot B_+ \prov  Q : \#
\justifies
[d_2] \prov {{d_2}} / Q : [ \lnot\lnot B_+  ]
\]
\justifies
[d_1, d_2] \prov \pair{{d_1}}{{d_2}} / (P\celse Q) : [ \lnot\lnot A_+ \tensor \lnot \lnot B_+ ]
\]
\justifies
  d : \lnot(\lnot\lnot A_+ \tensor \lnot \lnot B_+) \prov (\nu d_1d_2).d
\pair{{d_1}}{{d_2}}.(P\celse Q) : \#
\end{prooftree}
\]
Tensor read:
\[
\begin{prooftree}
\[
\[
\[
\justifies
y : \lnot A_- , z :  \lnot  B_- \prov  P  : \#
\]
\justifies
x : \lnot A_- \tensor \lnot  B_- \prov  \blet (y,z) = x \bin P  : \#
\]
\justifies
\prov \lambda x . \blet (y,z) = x \bin P  : [\lnot(\lnot A_- \tensor \lnot  B_-)]
\]
\justifies
  c : \lnot\lnot(\lnot A_- \tensor \lnot  B_-) \prov c(x).\blet (y,z) = x \bin P : \#
\end{prooftree}
\]


\end{document}
